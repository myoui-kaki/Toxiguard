ToxiGuard – Chat Toxicity Detection System

 Description:

 ToxiGuard   is a web-based chat toxicity detection system that uses   machine learning integration   to analyze user messages and determine whether they are   toxic or safe  .

The system processes text through:
- Text preprocessing (tokenization, lowercasing, and cleaning)
- Language detection (English and Filipino)
- Sentiment analysis to measure negativity and aggression
- Toxic pattern matching using a predefined list of offensive words and phrases
- Context awareness to reduce false positives

ToxiGuard is designed for educational and demonstration purposes, showcasing how   PHP  ,   Composer  , and   machine learning libraries   can be integrated into a functional web application.


 Important Instructions:

- This system is for   educational and demonstration purposes only  .
- Toxicity results are   not 100% accurate   and should not be used for legal or professional decisions.
- Do   not   enter personal, sensitive, or confidential information.
- The system analyzes text based on sentiment analysis and predefined toxic patterns.
- Messages may be marked toxic due to slang, strong emotions, or context limitations.
- Always test the system locally before deploying it online.
- Proper internet connection is required for the system to work correctly.
- Use responsibly and ethically.

How to Use the System

1. Open the ToxiGuard website.
2. Locate the   text input box   on the page.
3. Type or paste a chat message you want to analyze.
4. Click the   Analyze   or   Check Toxicity   button.
5. Wait for the system to process the message.
6. View the result displayed on the screen:
 Safe   – The message contains no toxic content.
 Toxic   – The message contains offensive, harmful, or aggressive language.
 Questionable - The message may contain mild offensive language, slang, or unclear context. Review carefully.
